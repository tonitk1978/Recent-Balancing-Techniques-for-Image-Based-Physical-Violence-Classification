{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA está disponible. PyTorch puede utilizar la GPU.\")\n",
    "    print(f\"Número de dispositivos CUDA disponibles: {torch.cuda.device_count()}\")\n",
    "    print(f\"Dispositivo CUDA actual: {torch.cuda.current_device()}\")\n",
    "    print(f\"Nombre del dispositivo CUDA actual: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"CUDA no está disponible. PyTorch utilizará la CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forzar el uso de la CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Usando la CPU\")\n",
    "\n",
    "# Medir tiempo de ejecución en CPU\n",
    "start_time_cpu = time.time()\n",
    "x = torch.randn(20000, 20000).to(device)\n",
    "y = torch.randn(20000, 20000).to(device)\n",
    "z = torch.matmul(x, y)  # Multiplicación de matrices en la CPU\n",
    "end_time_cpu = time.time()\n",
    "\n",
    "print(f\"Tiempo de ejecución en CPU: {end_time_cpu - start_time_cpu} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si CUDA está disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Usar la GPU\n",
    "    print(\"Usando la GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Medir tiempo de ejecución en GPU\n",
    "    start_time_gpu = time.time()\n",
    "    x = torch.randn(20000, 20000).to(device)\n",
    "    y = torch.randn(20000, 20000).to(device)\n",
    "    z = torch.matmul(x, y)  # Multiplicación de matrices en la GPU\n",
    "    end_time_gpu = time.time()\n",
    "\n",
    "    print(f\"Tiempo de ejecución en GPU: {end_time_gpu - start_time_gpu} segundos\")\n",
    "else:\n",
    "    print(\"La GPU no está disponible.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
